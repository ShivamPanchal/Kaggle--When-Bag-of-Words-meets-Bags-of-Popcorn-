{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing in a Kaggle Competition for Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shivam Panchal**\n",
    "**(shivam.panchal@mail.com)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, We will define a function, which will clean up the reviews for us**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great! Now, it's time to go ahead and load the data**\n",
    "**Link: https://www.kaggle.com/c/word2vec-nlp-tutorial/data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Datasets. We will use the labelled trained data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\users\\Shivam Panchal\\Desktop\\bags of popcorn\\Datasets\n"
     ]
    }
   ],
   "source": [
    "# Setting the work directory\n",
    "import os\n",
    "os.chdir('C://users/Shivam Panchal/Desktop/bags of popcorn/Datasets')\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('labeledTrainData.tsv', header = 0, delimiter=\"\\t\", quoting =3)\n",
    "\n",
    "test = pd.read_csv('testData.tsv', header = 0, delimiter=\"\\t\", quoting =3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Get the labels from our training dataset, to teach our classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we need to clean both the train and test data to get it ready for the next part of our program.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set movie reviews...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n",
      "Review 25000 of 25000\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "\n",
    "num_reviews = train[\"review\"].size\n",
    "print(\"Cleaning and parsing the training set movie reviews...\\n\")\n",
    "clean_train_reviews = []\n",
    "for i in xrange( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"Review %d of %d\" % ( i+1, num_reviews ))                                                                 \n",
    "    clean_train_reviews.append( review_to_words( train[\"review\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The next thing we are going to do is make TF-IDF (term frequency-interdocument frequency) vectors of our reviews. In case you are not familiar with what this is doing, essentially we are going to evaluate how often a certain term occurs in a review, but normalize this somewhat by how many reviews a certain term also occurs in.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''This can be a great technique for helping to determine which words (or ngrams of words) will make good features to classify a review as positive or negative.\n",
    "\n",
    "To do this, we are going to use the TFIDF vectorizer from scikit-learn. Then, decide what settings to use.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "Review 5000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 25000 of 25000\n"
     ]
    }
   ],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", \\\n",
    "                   quoting=3 )\n",
    "# Verify that there are 25,000 rows and 2 columns\n",
    "print(test.shape)\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "print(\"Cleaning and parsing the test set movie reviews...\")\n",
    "for i in xrange(0,num_reviews):\n",
    "    if( (i+1) % 5000 == 0 ):\n",
    "        print(\"Review %d of %d\" % (i+1, num_reviews))\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append( clean_review )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfv = TFIDFV(min_df=3, max_features=None,\n",
    "            strip_accents='unicode', analyzer='word', \n",
    "            token_pattern=r'\\w{1,}', stop_words= 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have the vectorization object, we need to run this on all of the data (both training and testing) to make sure it is applied to both datasets. This could take some time on your computer!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = clean_train_reviews + clean_test_reviews # Combine both to fit the TFIDF vectorization.\n",
    "\n",
    "tfv.fit(X_all) # This is the slow part!\n",
    "X_all = tfv.transform(X_all)\n",
    "\n",
    "X = X_all[:25000] # Separate back into training and test sets. \n",
    "X_test = X_all[25000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making our Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 47038)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''That means we have 25,000 training examples (or rows) and 47038 features (or columns). We need something that is going to be somewhat computationally efficient given how many features we have. Using something like a random forest to classify would be unwieldy (plus random forests can’t work with sparse matrices anyway yet in scikit-learn). That means we need something lightweight and fast that scales to many dimensions well. Some possible candidates are:\n",
    "\n",
    "Naive Bayes\n",
    "Logistic Regression\n",
    "SGD Classifier (utilizes Stochastic Gradient Descent for much faster runtime)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let’s just try all three as submissions to Kaggle and see how they perform.\n",
    "\n",
    "First up: Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Shivam Panchal\\Anaconda3\\envs\\gl-env\\lib\\site-packages\\sklearn\\svm\\base.py:874: DeprecationWarning: penalty='L2' has been deprecated in favor of penalty='l2' as of 0.16. Backward compatibility for the uppercase notation will be removed in 0.18\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise',\n",
       "       estimator=LogisticRegression(C=30, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='L2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={'C': [30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR = GridSearchCV(LR(C=30, class_weight=None, dual=True, fit_intercept=True,\n",
    "            intercept_scaling=1, penalty='L2', random_state=0, tol=0.0001), \n",
    "                        grid_values, scoring = 'roc_auc', cv = 20) \n",
    "\n",
    "# Try to set the scoring on what the contest is asking for. \n",
    "# The contest says scoring is for area under the ROC curve, so use this.\n",
    "\n",
    "model_LR.fit(X,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can investigate which parameters did the best and what scores they received by looking at the model_LR object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let’s make our Multinomial Naive Bayes object, and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "\n",
    "\n",
    "model_NB = MNB()\n",
    "model_NB.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One last classifier to try is the SGD classifier, which comes in handy when you need speed on a really large number of training examples/features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "       warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [6e-05, 7e-05, 8e-05, 0.0001, 0.0005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier as SGD\n",
    "\n",
    "\n",
    "  \n",
    "model_SGD = GridSearchCV(cv=20, estimator=SGD(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
    "           loss='modified_huber', n_iter=5, n_jobs=1, penalty='l2',\n",
    "           power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
    "           warm_start=False),\n",
    "           fit_params={}, iid=True, n_jobs=1,\n",
    "           param_grid={'alpha': [6e-05, 7e-05, 8e-05, 0.0001, 0.0005]},\n",
    "           pre_dispatch='2*n_jobs', refit=True,\n",
    "           scoring='roc_auc', verbose=0) # Find out which regularization parameter works the best. \n",
    "                            \n",
    "model_SGD.fit(X, y_train) # Fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Again, similar to the Logistic Regression model, we can see which parameter did the best.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "       warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [6e-05, 7e-05, 8e-05, 0.0001, 0.0005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''GridSearchCV(cv=20, estimator=SGD(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
    "           loss='modified_huber', n_iter=5, n_jobs=1, penalty='l2',\n",
    "           power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
    "           warm_start=False),\n",
    "           fit_params={}, iid=True, n_jobs=1,\n",
    "           param_grid={'alpha': [6e-05, 7e-05, 8e-05, 0.0001, 0.0005]},\n",
    "           pre_dispatch='2*n_jobs', refit=True,\n",
    "           scoring='roc_auc', verbose=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.96310, std: 0.00498, params: {'alpha': 6e-05},\n",
       " mean: 0.96334, std: 0.00498, params: {'alpha': 7e-05},\n",
       " mean: 0.96350, std: 0.00495, params: {'alpha': 8e-05},\n",
       " mean: 0.96363, std: 0.00498, params: {'alpha': 0.0001},\n",
       " mean: 0.95919, std: 0.00526, params: {'alpha': 0.0005}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SGD.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Looks like this beat our previous Logistic Regression model by a very small amount. Now that we have our three models, we can work on submitting our final scores in the proper format. It was found that submitting predicted probabilities of each score instead of the final predicted score worked better for evaluation from the contest participants, so we want to output this instead.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, do our Logistic Regression submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR_result = model_LR.predict_proba(X_test)[:,1] # We only need the probabilities that the movie review was a 7 or greater. \n",
    "LR_output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":LR_result}) # Create our dataframe that will be written.\n",
    "LR_output.to_csv('Logistic_Reg_Proj.csv', index=False, quoting=3) # Get the .csv file we will submit to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeat this for Multinomial Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MNB_result = model_NB.predict_proba(X_test)[:,1]\n",
    "MNB_output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":MNB_result})\n",
    "MNB_output.to_csv('MNB_Proj.csv', index = False, quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last, do the Stochastic Gradient Descent model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SGD_result = model_SGD.predict_proba(X_test)[:,1]\n",
    "SGD_output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":SGD_result})\n",
    "SGD_output.to_csv('SGD_Proj.csv', index = False, quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submitting the results**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
